---
title: "Examples"
linkTitle: "Examples"
weight: 6
description: >
  This section contains examples of using LWS with or without specific inference runtime.
---

This section provides practical examples of using LeaderWorkerSet (LWS) in various scenarios:

## Infrastructure Examples

- **[Horizontal Pod Autoscaler (HPA)](hpa/)** - Configure automatic scaling based on resource utilization

## Inference Runtime Examples

- **[vLLM](vllm/)** - Deploy distributed inference with vLLM on GPUs/TPUs
- **[TensorRT-LLM](tensorrt-llm/)** - High-performance inference with TensorRT-LLM
- **[SGLang](sglang/)** - Structured generation language inference
- **[LlamaCPP](llamacpp/)** - CPU-based inference with LlamaCPP

Each example includes detailed configuration files, deployment instructions, and best practices for production use.
